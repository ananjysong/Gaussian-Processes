{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics_JAX.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeNveqefiotIEN3lTTEssV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jysonganan/Gaussian-Processes/blob/master/Basics_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsEH_7oK7tGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "df0d65a0-11ee-4c1f-c984-2608cc98be78"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16039940570321362052, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 16550877450029741743\n",
              " physical_device_desc: \"device: XLA_CPU device\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYQios2l8l5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "48ed65c3-4fc5-49e3-fc22-bb0dd2d89077"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16145914453162090499, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 17979539285112938045\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 13771497194017127324\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 1334706176\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 3535907538658256442\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkO23oXq7hvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as onp\n",
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKXhZHtj7pFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate key which is used to generate random numbers\n",
        "key = random.PRNGKey(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ4Uec76Ec80",
        "colab_type": "text"
      },
      "source": [
        "Even simple matrix multiplication can be speed up quite a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFP46ZX88vZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f48d0354-df2c-47d2-de81-ae01fd06c33a"
      },
      "source": [
        "# Generate a random matrix\n",
        "x = random.uniform(key, (1000, 1000))\n",
        "# Compare running times of 3 different matrix multiplications\n",
        "%time y = onp.dot(x, x)\n",
        "%time y = np.dot(x, x)\n",
        "%time y = np.dot(x, x).block_until_ready()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 80.8 ms, sys: 15 ms, total: 95.7 ms\n",
            "Wall time: 62.2 ms\n",
            "CPU times: user 14.4 ms, sys: 8.1 ms, total: 22.5 ms\n",
            "Wall time: 11.3 ms\n",
            "CPU times: user 183 ms, sys: 86.1 ms, total: 269 ms\n",
            "Wall time: 147 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJQvJJKsE0R6",
        "colab_type": "text"
      },
      "source": [
        "## jit, grad, vmap\n",
        "\n",
        "##### jit - speed up\n",
        "##### grad - compute gradients\n",
        "##### vmap - easy for batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LbJ4oeCBrzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9c32c117-52f7-46a7-a1b4-a025d0086528"
      },
      "source": [
        "def ReLU(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "jit_ReLU = jit(ReLU)\n",
        "\n",
        "%time out = ReLU(x).block_until_ready()\n",
        "\n",
        "# Call jitted version to compile for evaluation time!\n",
        "%time jit_ReLU(x).block_until_ready()\n",
        "\n",
        "%time out = jit_ReLU(x).block_until_ready()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 73.9 ms, sys: 1.84 ms, total: 75.7 ms\n",
            "Wall time: 75.9 ms\n",
            "CPU times: user 22.6 ms, sys: 1.88 ms, total: 24.5 ms\n",
            "Wall time: 23.9 ms\n",
            "CPU times: user 2.08 ms, sys: 11 µs, total: 2.09 ms\n",
            "Wall time: 1.26 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsl7gFwGGBDm",
        "colab_type": "text"
      },
      "source": [
        "The next tool in JAX kit is grad. It's inherited from Autograd package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOnpxFd9F6k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "372e2625-babf-47d7-b72e-61fdea00d5cf"
      },
      "source": [
        "def FiniteDiffGrad(x):\n",
        "  return np.array((ReLU(x+1e-3)-ReLU(x-1e-3))/(2*1e-3))\n",
        "\n",
        "# Compare the Jax gradient with a finite difference approximation\n",
        "print(\"Jax Grad: \", jit(grad(jit(ReLU)))(2.))\n",
        "print(\"FD Gradient:\", FiniteDiffGrad(2.))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jax Grad:  1.0\n",
            "FD Gradient: 0.99998707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf6gStKQH5hP",
        "colab_type": "text"
      },
      "source": [
        "vmap - easy for batching\n",
        "\n",
        "Let’s say you have a 100 dimensional feature vector and want to process it by a linear layer with 512 hidden units & your ReLU activation. And let’s say you want to compute the layer activations for a batch with size 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZLZgW7LHKBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_dim = 32\n",
        "feature_dim = 100\n",
        "hidden_dim = 512\n",
        "\n",
        "# Generate a batch of vectors to process\n",
        "X = random.normal(key, (batch_dim, feature_dim))\n",
        "\n",
        "# Generate Gaussian weights and biases\n",
        "params = [random.normal(key, (hidden_dim, feature_dim)),\n",
        "          random.normal(key, (hidden_dim, ))]\n",
        "\n",
        "def relu_layer(params, x):\n",
        "    \"\"\" Simple ReLu layer for single sample \"\"\"\n",
        "    return ReLU(np.dot(params[0], x) + params[1])\n",
        "\n",
        "def batch_version_relu_layer(params, x):\n",
        "    \"\"\" Error prone batch version \"\"\"\n",
        "    return ReLU(np.dot(X, params[0].T) + params[1])\n",
        "\n",
        "def vmap_relu_layer(params, x):\n",
        "    \"\"\" vmap version of the ReLU layer \"\"\"\n",
        "    return jit(vmap(relu_layer, in_axes=(None, 0), out_axes=0))\n",
        "\n",
        "out = np.stack([relu_layer(params, X[i, :]) for i in range(X.shape[0])])\n",
        "out = batch_version_relu_layer(params, X)\n",
        "out = vmap_relu_layer(params, X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ6a-UtwLdH3",
        "colab_type": "text"
      },
      "source": [
        "We have stacked the vectors into a matrix such that our input has dimensions (batch_dim, feature_dim). We therefore need to provide vmap with batch dimension (0) in order to properly parallelize the computations. out_axes than specifies how to stack the individual samples outputs. In order to keep things consistent, we choose the first dimension to remain the batch dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH_m5qa8IaPG",
        "colab_type": "text"
      },
      "source": [
        "####References: \n",
        "https://roberttlange.github.io/posts/2020/03/blog-post-10/"
      ]
    }
  ]
}